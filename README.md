## ğŸ“˜ RAG Search Assistant â€“ Centrale MEDITERRANEE Edition

**Author**: Anne-Laure MEALIER
**License**: GPL-3.0
**Version**: 1.3
**Last Updated**: 2024-05-14


### ğŸ¯ Overview

This project implements a full **Retrieval-Augmented Generation (RAG)** pipeline, from **web crawling and enrichment** to **interactive question-answering** using a **local LLM** and **ChromaDB**.

It enables:

* Crawling technical documentation from any website
* Summarizing and enriching content using a local LLM via [Ollama](https://ollama.com/)
* Embedding text via SentenceTransformers (GPU supported)
* Storing embeddings in a **Chroma vector database**
* Querying this knowledge base through a **web interface** (Dash) using:

  * RAG only
  * LLM only
  * Hybrid (RAG + LLM)


## ğŸ“¦ Project Structure

```bash
project-root/
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ logo_centrale.svg         # Centrale MÃ©dietrranÃ©e logo for the web app
â”œâ”€â”€ logs/                         # Log files from pipeline and indexing
â”œâ”€â”€ chroma_db/                    # Persistent ChromaDB store
â”œâ”€â”€ enriched_pages.jsonl          # Output of RAG content enrichment
â”œâ”€â”€ generateRAG.py                # Crawl + enrich + embed + store
â”œâ”€â”€ vector_indexing.py           # Index JSONL to ChromaDB with weighted embeddings
â”œâ”€â”€ embed_worker.py              # Fast GPU-ready embedding subprocess
â”œâ”€â”€ searchEngineWebApp.py        # Dash app interface for querying
â””â”€â”€ README.md                     # You are here ğŸš€
```


## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

<details>
<summary>ğŸ“¦ Example <code>requirements.txt</code></summary>

```txt
dash
dash-bootstrap-components
markdown
xhtml2pdf
beautifulsoup4
requests
chromadb
sentence-transformers
numpy
torch
scikit-learn
bs4
tiktoken
asyncio
```
 

</details>


### 2. Run the Full RAG Pipeline

```bash
python generateRAG.py https://your.website.com/
```

* Crawls all HTML pages from the base URL
* Summarizes each with an LLM
* Generates keyword lists
* Chunks content and stores enriched JSONL
* Computes vector embeddings
* Stores everything into ChromaDB


### 3. (Optional) Re-index with Weighted Embeddings

```bash
python vector_indexing.py enriched_pages.jsonl
```

* Uses a weighted combination of **summary** and **keywords**
* Optimized for fast GPU embedding


### 4. Launch the Dash Web App

```bash
python searchEngineWebApp.py
```

* Open `http://127.0.0.1:8050` in your browser
* Ask questions in English or French
* Toggle modes: Hybrid, RAG-only, or LLM-only
* Download responses as PDFs
* View sources with similarity scores


## ğŸ§  Architecture

### 1. **generateRAG.py**

* Crawls HTML pages from a base URL
* Extracts text, enriches with LLM (summary + keywords)
* Outputs a `.jsonl` file
* Embeds chunks and stores in ChromaDB

### 2. **vector\_indexing.py**

* (Optional) Reindexes `.jsonl` with custom weights:

  * `0.8 * summary + 0.2 * keywords`
* Uses `paraphrase-multilingual-MiniLM` with GPU acceleration

### 3. **embed\_worker.py**

* Lightweight subprocess for embedding queries
* Used by the Dash app
* Returns a vector from stdin JSON input

### 4. **searchEngineWebApp.py**

* Frontend with Dash and Bootstrap (CYBORG theme)
* User asks question â†’ Query is embedded â†’ Search ChromaDB
* LLM answers using RAG content or own knowledge
* PDF export and source display included


## ğŸ–¼ï¸ Web Interface

* ğŸ§  Query interface with text area
* ğŸ” Modes: RAG-only, Hybrid, LLM-only
* ğŸ“š Show source URLs and scores (sorted by relevance)
* ğŸ“„ PDF export of full Q\&A session


## âš™ï¸ Configuration

Modify these constants in `searchEngineWebApp.py`:

```python
TOP_K = 50                # Number of top matches to retrieve
THRESHOLD_GOOD = 0.70     # Minimum score to consider a match relevant
DEFAULT_LLM_MODEL = "gemma3:4b"  # Ollama model to use
DEFAULT_QUERY_MODE = "rag_only"  # Starting mode
```


## ğŸ“Œ Notes

* The system assumes Ollama is running locally at `http://localhost:11434`
* Embedding and inference prefer GPU (if available)
* All logs are stored in `/logs` with timestamps
* Files in `/assets` (like logos) are auto-served by Dash


## ğŸ§ª Testing

To test locally:

```bash
# Crawl test site
python generateRAG.py https://doc.cc.in2p3.fr/

# Index generated file
python vector_indexing.py enriched_pages.jsonl

# Launch app
python searchEngineWebApp.py
```

## ğŸ“„ License

This project is licensed under the [GPL-3.0 License](https://www.gnu.org/licenses/gpl-3.0.html)

You are free to use, modify, and distribute this software, provided that:

The source code remains open and publicly accessible under the same license.
Any derivative works or modified versions are also released under GPL-3.0.
Appropriate credit is given to the original author.


## ğŸ‘©â€ğŸ”¬ Author

**Anne-Laure MEALIER**
Centrale MÃ©diterranÃ©e â€“ 2024
Optimized for GPU acceleration and on-premise privacy
